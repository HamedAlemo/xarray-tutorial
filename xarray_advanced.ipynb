{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xarray Interpolation, Groupby, Resample, Rolling, and Coarsen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attribution**: This notebook is a revision of the [Xarray Interpolation, Groupby, Resample, Rolling, and Coarsen notebook](https://earth-env-data-science.github.io/lectures/xarray/xarray-part2.html) by Ryan Abernathey from [An Introduction to Earth and Environmental Data Science](https://earth-env-data-science.github.io/intro.html). Thanks to Aiyin Zhang for preparing this notebook. \n",
    "\n",
    "In this lesson, we cover some more advanced aspects of `xarray`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access this notebook (in a Docker image) on this [GitHub repo](https://github.com/HamedAlemo/xarray-tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous lesson on `xarray`, we learned how to select data based on its dimension coordinates and align data with dimension different coordinates.\n",
    "But what if we want to estimate the value of the data variables at _different coordinates_.\n",
    "This is where interpolation comes in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we write it out explicitly so we can see each point.\n",
    "x_data = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "f = xr.DataArray(x_data**2, dims=['x'], coords={'x': x_data})\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.plot(marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.sel(x=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have data on the integer points in x.\n",
    "But what if we wanted to estimate the value at, say, 4.5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.sel(x=4.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolation to the rescue!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.interp(x=4.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolation uses [scipy.interpolate](https://docs.scipy.org/doc/scipy/reference/interpolate.html) under the hood.\n",
    "There are different modes of interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.interp(x=4.5, method='linear').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.interp(x=4.5, method='nearest').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.interp(x=4.5, method='cubic').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can interpolate to a whole new set of coordinates at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_new = x_data + 0.5\n",
    "f_interp_linear = f.interp(x=x_new, method='linear')\n",
    "f_interp_cubic = f.interp(x=x_new, method='cubic')\n",
    "f.plot(marker='o', label='original')\n",
    "f_interp_linear.plot(marker='o', label='linear')\n",
    "f_interp_cubic.plot(marker='o', label='cubic')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that values outside of the original range are not supported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_interp_cubic.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "You can apply interpolation to any dimension, and even to multiple dimensions at a time.\n",
    "(Multidimensional interpolation only supports `mode='nearest'` and `mode='linear'`.)\n",
    "But keep in mind that `xarray` has no built-in understanding of geography.\n",
    "If you use `interp` on lat / lon coordinates, it will just perform naive interpolation of the lat / lon values.\n",
    "More sophisticated treatment of spherical geometry requires another package such as [xesmf](https://xesmf.readthedocs.io/).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data from NetCDF Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NetCDF (Network Common Data Format) is the most widely used format for distributing geoscience data. NetCDF is maintained by the [Unidata](https://www.unidata.ucar.edu/) organization.\n",
    "\n",
    "Below we quote from the [NetCDF website](https://www.unidata.ucar.edu/software/netcdf/docs/faq.html#whatisit):\n",
    "\n",
    ">NetCDF (network Common Data Form) is a set of interfaces for array-oriented data access and a freely distributed collection of data access libraries for C, Fortran, C++, Java, and other languages. The netCDF libraries support a machine-independent format for representing scientific data. Together, the interfaces, libraries, and format support the creation, access, and sharing of scientific data.\n",
    ">\n",
    ">NetCDF data is:\n",
    ">\n",
    "> - Self-Describing. A netCDF file includes information about the data it contains.\n",
    "> - Portable. A netCDF file can be accessed by computers with different ways of storing integers, characters, and floating-point numbers.\n",
    "> - Scalable. A small subset of a large dataset may be accessed efficiently.\n",
    "> - Appendable. Data may be appended to a properly structured netCDF file without copying the dataset or redefining its structure.\n",
    "> - Sharable. One writer and multiple readers may simultaneously access the same netCDF file.\n",
    "> - Archivable. Access to all earlier forms of netCDF data will be supported by current and future versions of the software.\n",
    "\n",
    "`xarray` is designed to make reading netCDF files in python as easy, powerful, and flexible as possible. (See [xarray netCDF docs](http://xarray.pydata.org/en/latest/io.html#netcdf) for more details.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we download and load some the NASA [GISSTemp](https://data.giss.nasa.gov/gistemp/) global temperature anomaly dataset. The original file is located at https://data.giss.nasa.gov/pub/gistemp/gistemp1200_GHCNv4_ERSSTv5.nc.gz, but their server is non-responsive at the time of publication of this notebook. So we will use the mirror server from Zenodo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pooch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "gistemp_file = pooch.retrieve(\n",
    "    'https://zenodo.org/records/13963679/files/gistemp1200_GHCNv4_ERSSTv5.nc',\n",
    "    known_hash=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(gistemp_file)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.tempanomaly.isel(time=-1).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.tempanomaly.mean(dim=('lon', 'lat')).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the temperature anomally for the grid near Worcester. (Worcester's coordinates: latitude: 42.2626; longtitude: -71.8023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.tempanomaly.sel(lat=42.2626, lon=-71.8023, method='nearest').plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you need to define `method` since the corresponding values for Worcester latitude and longitude do not exist in the `DataArray`'s coordinates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`xarray` copies `pandas'` very useful groupby functionality, enabling the \"split / apply / combine\" workflow on `xarray` `DataArray`s and `Dataset`s. In the first part of the lesson, we will learn to use groupby by analyzing sea-surface temperature data.\n",
    "\n",
    "\n",
    "First we load a dataset. We will use the [NOAA Extended Reconstructed Sea Surface Temperature (ERSST) v5](https://www.ncdc.noaa.gov/data-access/marineocean-data/extended-reconstructed-sea-surface-temperature-ersst-v5) product, a widely used and trusted gridded compilation of historical data going back to 1854.\n",
    "\n",
    "Since the data is provided via an [OPeNDAP](https://en.wikipedia.org/wiki/OPeNDAP) server, we can load it directly without downloading anything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = 'http://www.esrl.noaa.gov/psd/thredds/dodsC/Datasets/noaa.ersst.v5/sst.mnmean.nc'\n",
    "ds = xr.open_dataset(url, drop_variables=['time_bnds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = ds.sel(time=slice('1960', '2022'))\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some basic visualizations of the data, just to make sure it looks reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.sst.sel(time = '1960-01-01').plot(ax = ax, vmin=-2, vmax=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that xarray correctly parsed the time index, resulting in a Pandas datetime index on the time dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.sst.sel(lon=300, lat=50).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the plot, the timeseries at any one point is totally dominated by the seasonal cycle. We would like to remove this seasonal cycle (called the \"climatology\") in order to better see the long-term variaitions in temperature. We will accomplish this using **groupby**.\n",
    "\n",
    "The syntax of `xarray`'s groupby is almost identical to `pandas`.\n",
    "We will first apply groupby to a single `DataArray`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important argument is `group`: this defines the unique values we will use to \"split\" the data for grouped analysis. We can pass either a `DataArray` or a name of a variable in the dataset. Lets first use a `DataArray`. Just like with `pandas`, we can use the time index to extract specific components of dates and times. `xarray` uses a special syntax for this `.dt`, called the `DatetimeAccessor`.\n",
    "\n",
    "See a list of datatime properties you can access through .dt [here](https://pandas.pydata.org/docs/user_guide/timeseries.html#time-date-components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.time.dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.time.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.time.dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these arrays in a groupby operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gb = ds.sst.groupby(ds.time.dt.month)\n",
    "gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`xarray` also offers a more concise syntax when the variable you're grouping on is already present in the dataset. This is identical to the previous line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gb = ds.sst.groupby('time.month')\n",
    "gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data are split, we can manually iterate over the group. The iterator returns the key (group name) and the value (the actual dataset corresponding to that group) for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for group_name, group_da in gb:\n",
    "    print(group_name) # stop after first iteration\n",
    "    break\n",
    "group_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map & Combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have groups defined, it's time to \"apply\" a calculation to the group. Like in `pandas`, these calculations can either be:\n",
    "- _aggregation_: reduces the size of the group\n",
    "- _transformation_: preserves the group's full size\n",
    "\n",
    "At then end of the apply step, `xarray` will automatically combine the aggregated / transformed groups back into a single object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```{warning}\n",
    "Xarray calls the \"apply\" step `map`. This is different from Pandas!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gb.map?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like `pandas`, `xarray`'s groupby object has many built-in aggregation operations (e.g. `mean`, `min`, `max`, `std`, etc):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sst_mm = gb.mean(dim='time')\n",
    "sst_mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.map` accepts as its argument a function. We can pass an existing function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gb.map(np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we specified no extra arguments (like `axis`) the function was applied over all space and time dimensions. This is not what we wanted. Instead, we could define a custom function. This function takes a single argument --the group dataset-- and returns a new dataset to be combined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def time_mean(a):\n",
    "    return a.mean(dim='time')\n",
    "\n",
    "sst_mm = gb.map(time_mean)\n",
    "sst_mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we did what we wanted to do: calculate the climatology at every point in the dataset. Let's look at the data a bit.\n",
    "\n",
    "_Climatlogy at a specific point in the North Atlantic_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sst_mm.sel(lon=300, lat=-50).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "_Zonal Mean Climatology_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sst_mm.mean(dim='lon').transpose().plot.contourf(levels=12, vmin=-2, vmax=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Difference between January and July Climatology_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(sst_mm.sel(month=1) - sst_mm.sel(month=7)).plot(vmax=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to _remove_ this climatology from the dataset, to examine the residual, called the _anomaly_, which is the interesting part from a climate perspective.\n",
    "Removing the seasonal climatology is a perfect example of a transformation: it operates over a group, but doesn't change the size of the dataset. Here is one way to code it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_time_mean(x):\n",
    "    return x - x.mean(dim='time')\n",
    "\n",
    "ds_anom = ds.groupby('time.month').map(remove_time_mean)\n",
    "ds_anom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "In the above example, we applied `groupby` to a `Dataset` instead of a `DataArray`.\n",
    "```\n",
    "\n",
    "Xarray makes these sorts of transformations easy by supporting _groupby arithmetic_.\n",
    "This concept is easiest explained with an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gb = ds.groupby('time.month')\n",
    "ds_anom = gb - gb.mean(dim='time')\n",
    "ds_anom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can view the climate signal without the overwhelming influence of the seasonal cycle.\n",
    "\n",
    "_Timeseries at a single point in the North Atlantic_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_anom.sst.sel(lon=300, lat=50).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Difference between Jan. 1 2022 and Jan. 1 1960_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(ds_anom.sel(time='2022-01-01') - ds_anom.sel(time='1960-01-01')).sst.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouby-Related: Resample, Rolling, Coarsen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Resample](https://docs.xarray.dev/en/v2023.10.1/generated/xarray.Dataset.resample.html) in `xarray` is nearly identical to `pandas`.\n",
    "**It can be applied only to time-index dimensions.** Here we compute the five-year mean.\n",
    "It is effectively a group-by operation, and uses the same basic syntax.\n",
    "Note that resampling changes the length of the the output array.\n",
    "\n",
    "See the [list](https://pandas.pydata.org/docs/user_guide/timeseries.html#offset-aliases) of string aliases for time series frequencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_anom_resample = ds_anom.resample(time='5YE').mean(dim='time')\n",
    "ds_anom_resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_anom.sst.sel(lon=300, lat=50).plot()\n",
    "ds_anom_resample.sst.sel(lon=300, lat=50).plot(marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(ds_anom_resample.sel(time='2015-01-01', method='nearest') -\n",
    " ds_anom_resample.sel(time='1965-01-01', method='nearest')).sst.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Rolling](https://docs.xarray.dev/en/v2023.10.1/generated/xarray.Dataset.rolling.html#xarray.Dataset.rolling) is also similar to `pandas`.\n",
    "It does not change the length of arrays.\n",
    "Instead, it allows a moving window to be applied to the data at each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_anom_rolling = ds_anom.rolling(time=12, center=True).mean()\n",
    "ds_anom_rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_anom.sst.sel(lon=300, lat=50).plot(label='monthly anom')\n",
    "ds_anom_resample.sst.sel(lon=300, lat=50).plot(marker='o', label='5 year resample')\n",
    "ds_anom_rolling.sst.sel(lon=300, lat=50).plot(label='12 month rolling mean', color='k')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coarsen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coarsen is a simple way to reduce the size of your data along one or more axes.\n",
    "It is very similar to `resample` when operating on time dimensions; the key difference is that coarsen only operates on fixed blocks of data, irrespective of the coordinate values, while resample actually looks at the coordinates to figure out, e.g. what month a particular data point is in. \n",
    "\n",
    "For regularly-spaced monthly data beginning in January, the following should be equivalent to annual resampling.\n",
    "However, results would be different for irregularly-spaced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.coarsen(time=12, boundary = 'exact').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coarsen also works on spatial coordinates (or any coordiantes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_coarse = ds.coarsen(lon=4, lat=4, boundary='pad').mean()\n",
    "ds_coarse.sst.isel(time=0).plot(vmin=2, vmax=30, figsize=(12, 5), edgecolor='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
